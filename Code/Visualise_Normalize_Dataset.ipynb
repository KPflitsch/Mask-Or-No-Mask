{
 "cells": [
  {
   "cell_type": "code",
   "id": "c8a498fcd0ab03b7",
   "metadata": {
    "id": "c8a498fcd0ab03b7"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "8730ce03a0716497"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Mask-Or-No-Mask'\n",
    "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ],
   "id": "8730ce03a0716497"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T18:21:16.813033Z",
     "start_time": "2025-04-09T18:21:16.790094Z"
    },
    "id": "13a954552ee77421"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ],
   "id": "13a954552ee77421"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T18:21:16.829009Z",
     "start_time": "2025-04-09T18:21:16.822008Z"
    },
    "id": "47ff333279144b6c"
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Path to images and labels\n",
    "# -------------------------- Paths for PyCharm --------------------------\n",
    "\n",
    "DATASET_PATH = \"../CW_Dataset\"\n",
    "TRAIN_IMAGE_PATH = \"../CW_Dataset/train/images\"\n",
    "TRAIN_LABEL_PATH = \"../CW_Dataset/train/labels\"\n",
    "TEST_IMAGE_PATH = \"../CW_Dataset/test/images\"\n",
    "TEST_LABEL_PATH = \"../CW_Dataset/test/labels\"\n",
    "SAVE_DIR = \"../npy_dataset\"\n",
    "\n",
    "# -------------------------- Paths for PyCharm --------------------------\n",
    "\n",
    "# -------------------------- Paths for Colab --------------------------\n",
    "\n",
    "# DATASET_PATH = \"/content/drive/MyDrive/Mask-Or-No-Mask/CW_Dataset\"\n",
    "# TRAIN_IMAGE_PATH = f\"{DATASET_PATH}/train/images\"\n",
    "# TRAIN_LABEL_PATH = f\"{DATASET_PATH}/train/labels\"\n",
    "# TEST_IMAGE_PATH = f\"{DATASET_PATH}/test/images\"\n",
    "# TEST_LABEL_PATH = f\"{DATASET_PATH}/test/labels\"\n",
    "# SAVE_DIR = f\"{DATASET_PATH}/../npy_dataset\"\n",
    "\n",
    "# -------------------------- Paths for Colab --------------------------\n"
   ],
   "id": "47ff333279144b6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T18:21:17.540089Z",
     "start_time": "2025-04-09T18:21:16.863898Z"
    },
    "id": "initial_id"
   },
   "cell_type": "code",
   "source": [
    "def show_random_images(ip, lp):\n",
    "    # Map to associate value with category\n",
    "    label_map = {\n",
    "        '0': \"No mask\",\n",
    "        '1': \"Properly worn mask\",\n",
    "        '2': \"Improperly worn mask\"\n",
    "    }\n",
    "\n",
    "    # Get all images\n",
    "    image_files = [f for f in os.listdir(ip) if f.lower().endswith('.jpeg')]\n",
    "\n",
    "    # Select random images\n",
    "    num_samples = 6\n",
    "    sampled_images = random.sample(image_files, num_samples)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, img_name in enumerate(sampled_images):\n",
    "        img_path = os.path.join(ip, img_name)\n",
    "\n",
    "        # Read image\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert to RGB for matplotlib\n",
    "\n",
    "        # Find label for image\n",
    "        label_filename = os.path.splitext(img_name)[0] + '.txt'\n",
    "        label_path = os.path.join(lp, label_filename)\n",
    "\n",
    "        # Read label\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label_index = f.read().strip()\n",
    "            label_text = label_map.get(label_index, \"Unknown label\")\n",
    "        else:\n",
    "            label_text = 'Unknown label'\n",
    "\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{img_name}\\n{label_text}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_random_images(TRAIN_IMAGE_PATH, TRAIN_LABEL_PATH)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "83857ee804fe46ad"
   },
   "cell_type": "markdown",
   "source": [
    "- Initially thought of using padding to make all images the same size\n",
    "- Realised this might cause issues with edge detection, because of the sharp border of the black/white pixels I will be adding\n",
    "\t- This could cause big issues down the line with feature descriptors\n",
    "- Thought about adding padding then using a pre-trained face detection model to crop into the faces and pull a consistent size\n",
    "- Realised, if I'm using face detection, then why bother adding padding as the face detection should only pull the face regardless of image size.\n",
    "- Options\n",
    "\t- OpenCV Haar Cascade Classifier\n",
    "\t- OpenCV DNN Face Detection\n",
    "\t- dlib.get_frontal_face()\n",
    "- Decided on using OpenCVs DNN Face Detection model\n",
    "- Learnt that that model needs images of at least 100x100 to be nicely accurate\n",
    "- Realised, that due to the vast different in the sizes of the images even if the image size wasn't an issue, the face detection model would probably poorly handle up/downscaling of the images\n",
    "\n",
    "- Going to write code to allow me to find the frequency of the sizes of the images and visualise them, that way I can choose the best size to normalise too. I.e.\n",
    "\t- Most images are in the range 10x10 - 70x70 then 64x64 seems fitting\n",
    "\t- Most images are in the range 100x100 - 150x150 then 128x128 seems fitting"
   ],
   "id": "83857ee804fe46ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T18:21:29.970634Z",
     "start_time": "2025-04-09T18:21:17.592950Z"
    },
    "id": "4a3d550617c14fc"
   },
   "cell_type": "code",
   "source": [
    "image_sizes = []\n",
    "\n",
    "for filename in os.listdir(TRAIN_IMAGE_PATH):\n",
    "    if filename.lower().endswith('.jpeg'):\n",
    "        img_path = os.path.join(TRAIN_IMAGE_PATH, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is not None:\n",
    "            h, w = img.shape[:2]\n",
    "            rounded_sizes = (w // 10 * 10, h // 10 * 10)\n",
    "            image_sizes.append(rounded_sizes)\n",
    "\n",
    "counter = Counter(image_sizes)\n",
    "\n",
    "sorted_sizes = sorted(counter.items(), key=lambda x: (x[0][0], x[0][1]))\n",
    "labels = [f\"{w}x{h}\" for (w, h), _ in sorted_sizes]\n",
    "counts = [count for _, count in sorted_sizes]\n",
    "\n",
    "skip = 5\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, counts)\n",
    "plt.xticks(ticks = range(0, len(labels), skip), labels = labels[::skip], rotation = 45, ha = 'right')\n",
    "plt.title('Freq of image sizes (rounded to closest 10 pixels)')\n",
    "plt.xlabel('Image size')\n",
    "plt.ylabel('Frequency')\n",
    "#plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4a3d550617c14fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "92bab7a6591a6f47"
   },
   "cell_type": "markdown",
   "source": [
    "- Based on the results from the visualisation I can see that most of the images are on the smaller side therefore I will go 64x64.\n",
    "\t- I questioned whether I should choose a rectangular size rather than square but upon research learned that\n",
    "\t    - 64x64 is somewhat of a standard\n",
    "\t    - It is best for model compatibility\n",
    "\t    - Allows for uniform cell layout for HOG descriptors\n",
    "\t    - can easily augment the image (flip/rotate)\n",
    "\t    - etc.\n",
    "\n",
    "- Adding padding to the image\n",
    "    - Maintaining aspect ratio\n",
    "    - Centering image\n",
    "    - Padding colour will be black"
   ],
   "id": "92bab7a6591a6f47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T18:21:30.017472Z",
     "start_time": "2025-04-09T18:21:30.004508Z"
    },
    "id": "b42da42b2cbd29"
   },
   "cell_type": "code",
   "source": [
    "def resize_with_padding(img, target_size=(64, 64), pad_colour=0):\n",
    "    # Get image height and width\n",
    "    h, w = img.shape[:2]\n",
    "    # Target height and width\n",
    "    th, tw = target_size\n",
    "\n",
    "    # Set interpolation function based downscaling or upscaling\n",
    "    interpolation = cv2.INTER_AREA if h > th or w > tw else cv2.INTER_CUBIC\n",
    "\n",
    "    # Calculate aspect ratio of input image and maintain it for maintaining that aspect ratio\n",
    "    aspect_ratio = float(h) / float(w)\n",
    "    if aspect_ratio > 1:\n",
    "        new_w = tw\n",
    "        new_h = int(new_w / aspect_ratio)\n",
    "    else:\n",
    "        new_h = th\n",
    "        new_w = int(new_h * aspect_ratio)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_w, new_h), interpolation=interpolation)\n",
    "\n",
    "    # Calculate amount of padding needed, and keeping image centered\n",
    "    pad_top = (th - new_h) // 2\n",
    "    pad_bottom = th - new_h - pad_top\n",
    "    pad_left = (tw - new_w) // 2\n",
    "    pad_right = tw - new_w - pad_left\n",
    "\n",
    "    # Add the padding (chosen colour is black)\n",
    "    padded_image = cv2.copyMakeBorder(resized_img, pad_top, pad_bottom, pad_left, pad_right, borderType = cv2.BORDER_CONSTANT, value = pad_colour)\n",
    "\n",
    "    return padded_image"
   ],
   "id": "b42da42b2cbd29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "adcce72d5441c847"
   },
   "cell_type": "markdown",
   "source": [
    "- Loading normalized images\n",
    "    - Make images greyscale\n",
    "    - Normalize pixel values\n",
    "    - Save all the images as np.array so I don't have to do this every time\n",
    "    - Add the images and labels to lists for ease of use"
   ],
   "id": "adcce72d5441c847"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T18:36:58.853895Z",
     "start_time": "2025-04-09T18:36:58.832951Z"
    },
    "id": "a72f49ea670ca2aa"
   },
   "cell_type": "code",
   "source": [
    "def load_normalize_images(set_type=\"train\"):\n",
    "    # Choose paths based on train or test data\n",
    "    if set_type == \"train\":\n",
    "        image_dir = TRAIN_IMAGE_PATH\n",
    "        label_dir = TRAIN_LABEL_PATH\n",
    "        save_name_suffix = \"train\"\n",
    "    elif set_type == \"test\":\n",
    "        image_dir = TEST_IMAGE_PATH\n",
    "        label_dir = TEST_LABEL_PATH\n",
    "        save_name_suffix = \"test\"\n",
    "    else:\n",
    "        raise ValueError(\"set_type must be 'train' or 'test'\")\n",
    "\n",
    "    # List to store images and labels\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Iterate through all the images in the target dir\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if not img_file.lower().endswith('.jpeg'):\n",
    "            continue\n",
    "\n",
    "        # Make paths to each image and label\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "        # Make image greyscale\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Skip if error with image\n",
    "        if img is None or not os.path.exists(label_path):\n",
    "            continue\n",
    "\n",
    "        # Get the label that matches the image\n",
    "        with open(label_path, 'r') as f:\n",
    "            label_string = f.read().strip()\n",
    "\n",
    "        # Skip if the labels are not valid\n",
    "        if label_string not in ['0', '1', '2']:\n",
    "            continue\n",
    "\n",
    "        # Convert label to int for ease of use later\n",
    "        label = int(label_string)\n",
    "\n",
    "        # Resize image with padding if necessary\n",
    "        normalized_img = resize_with_padding(img)\n",
    "\n",
    "        # Normalize pixel values\n",
    "        normalized_img = normalized_img.astype(np.float32) / 255.0\n",
    "\n",
    "        # Add normalized image to list\n",
    "        X.append(normalized_img)\n",
    "        y.append(label)\n",
    "\n",
    "    # Create numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Save the files as .npy\n",
    "    np.save(os.path.join(SAVE_DIR, f'X_{save_name_suffix}.npy'), X)\n",
    "    np.save(os.path.join(SAVE_DIR, f'y_{save_name_suffix}.npy'), y)\n",
    "\n",
    "    return X, y"
   ],
   "id": "a72f49ea670ca2aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "60775f15b5560a1e"
   },
   "cell_type": "markdown",
   "source": [
    "- Visualise the normalised images to make sure it all looks good\n",
    "- I want the images to be saved as 2D arrays so I'll remove the singleton channel as well (if there is one present)"
   ],
   "id": "60775f15b5560a1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T18:21:30.127642Z",
     "start_time": "2025-04-09T18:21:30.114680Z"
    },
    "id": "2cfd701e34c0abd"
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def show_random_normalized_images(X, y, label_map = None, num_samples = 6, dataset_name=\"Dataset\"):\n",
    "    # Match the labels with the correct categories\n",
    "    if label_map is None:\n",
    "        label_map = {\n",
    "            0: \"No mask\",\n",
    "            1: \"Properly worn mask\",\n",
    "            2: \"Improperly worn mask\"\n",
    "        }\n",
    "\n",
    "    # Randomly select the images from the dataset (I don't want over 2000 images all being shown haha)\n",
    "    indices = random.sample(range(len(X)), num_samples)\n",
    "\n",
    "    # Create the grid to display images\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Add title so I know what dataset is being used\n",
    "    plt.suptitle(f'Random samples from {dataset_name}', fontsize=20)\n",
    "\n",
    "    # Plot image with label\n",
    "    for i, idx in enumerate(indices):\n",
    "        img = X[idx]\n",
    "        label = y[idx]\n",
    "        label_text = label_map.get(label, \"Unknown\")\n",
    "\n",
    "        # Remove singleton channel\n",
    "        if img.ndim == 3 and img.shape[-1] == 1:\n",
    "            img = img.squeeze()\n",
    "\n",
    "        # Create the plot\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(label_text)\n",
    "        plt.axis('off')\n",
    "\n",
    "    # Display\n",
    "    plt.tight_layout(rect=(0.0, 0.0, 1.0, 1.0))\n",
    "    plt.show()"
   ],
   "id": "2cfd701e34c0abd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T18:38:10.455314Z",
     "start_time": "2025-04-09T18:37:36.008901Z"
    },
    "id": "3471804284e77fa4"
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train = load_normalize_images(\"train\")\n",
    "X_test, y_test = load_normalize_images(\"test\")\n",
    "\n",
    "\n",
    "print(\"Train images:\", len(X_train))\n",
    "print(\"Test images:\", len(X_test))\n",
    "\n",
    "show_random_normalized_images(X_train, y_train, dataset_name = \"Training Data\")\n",
    "show_random_normalized_images(X_test, y_test, dataset_name = \"Test Data\")\n"
   ],
   "id": "3471804284e77fa4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
